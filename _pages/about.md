---
permalink: /
title: "ğŸ¦˜Teng-Fang â€“ Master Student in NYCU"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## ğŸ‘‹ Hi! Iâ€™m Teng-Fang Hsiao (è•­ç™»æ–¹)

Iâ€™ve been pursuing my **Masterâ€™s degree of Electrical Engineering at National Yang Ming Chiao Tung University** since **September 2024** ğŸ“.

My research focuses on **Computer Vision** and **AIGC**.  
I previously worked on **2D generation and image editing**, and I'm now exploring **3D and video generation** ğŸ§ ğŸ–¼ï¸ğŸ¥.

I'm the **first author** of publications at **ICCV 2025**, **AAAI 2025**, and **WACV 2024**,  
and also a **co-author** on a paper accepted at **ICIP 2025** ğŸ“„âœ¨.

I'm always **open to academic discussions, collaborations, or research opportunities ğŸ¤** â€” feel free to reach out!

<div style="display: flex; flex-wrap: wrap; align-items: flex-start; gap: 10px;">
  <img src="images/tf_ti2i.png" alt="teaser" style="width: 100%; max-width: 800px; height: auto;">
  <div style="flex: 1; min-width: 200px;">
    <b style="display: inline-block; max-width: 100%; word-break: break-word;">
    TF-TI2I: Training-Free Text-and-Image-to-Image Generation via Multi-Modal Implicit-Context Learning in Text-to-Image Models
    </b><br>
    <i><u>Teng-Fang Hsiao</u>, Bo-Kai Ruan, Yi-Lun Wu, Tzu-Ling Lin, Hong-Han Shuai</i> <br>
    <i>To be apper on International Conference on Computer Vision (ICCV), 2025</i> <br>
    Augment your T2I models with arbitrary number of images as references in a Training-Free manner ğŸ¦–ğŸ–¼ï¸ğŸ”¥<br> 
    <a href="https://arxiv.org/abs/2503.15283">pdf</a> /
    <a href="https://github.com/BlueDyee/TF-TI2I">GitHub</a> /
    <a href="https://bluedyee.github.io/TF-TI2I_page/">Project page</a>
  </div>
</div>

<div style="display: flex; flex-wrap: wrap; align-items: flex-start; gap: 10px;">
  <img src="images/tf_gph.png" alt="teaser" style="width: 100%; max-width: 800px; height: auto;">
  <div style="flex: 1; min-width: 200px;">
    <b style="display: inline-block; max-width: 100%; word-break: break-word;">
    Training-and-Prompt-Free General Painterly Harmonization via Zero-Shot Disentenglement on Style and Content References
    </b><br>
    <i><u>Teng-Fang Hsiao</u>, Bo-Kai Ruan, Hong-Han Shuai</i><br>
    <i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2025</i><br>
    Harmonizing any copy and pasted objects in a Training-Free manner ğŸ–¼ï¸ğŸ‘©ğŸ»â€ğŸ¨ğŸ¨<br> 
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32368">pdf</a> /
    <a href="https://github.com/BlueDyee/TF-GPH">GitHub</a> /
  </div>
</div>

<div style="display: flex; flex-wrap: wrap; align-items: flex-start; gap: 10px;">
  <img src="images/light_attack.png" alt="teaser" style="width: 100%; max-width: 800px; height: auto;">
  <div style="flex: 1; min-width: 200px;">
    <b style="display: inline-block; max-width: 100%; word-break: break-word;">
    Natural light can also be dangerous: Traffic sign misinterpretation under adversarial natural light attacks
    </b><br>
    <i><u>Teng-Fang Hsiao</u>, Bo-Lun Huang, Zi-Xiang Ni, Yan-Ting Lin, Hong-Han Shuai, Yung-Hui Li, Wen-Huang Cheng</i> <br>
    <i>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2025</i> <br>
    Real world physical attack on Autonomus Driving with Natural Light ğŸ’¡ğŸš—âš ï¸<br> 
    <a href="https://openaccess.thecvf.com/content/WACV2024/html/Hsiao_Natural_Light_Can_Also_Be_Dangerous_Traffic_Sign_Misinterpretation_Under_WACV_2024_paper.html">pdf</a> /
    <a href="https://github.com/BlueDyee/natural-light-attack">GitHub</a> /
  </div>
</div>

<div style="display: flex; flex-wrap: wrap; align-items: flex-start; gap: 10px;">
  <img src="images/freecond.png" alt="teaser" style="width: 100%; max-width: 800px; height: auto;">
  <div style="flex: 1; min-width: 200px;">
    <b style="display: inline-block; max-width: 100%; word-break: break-word;">
    FreeCond: Free Lunch in the Input Conditions of Text-Guided Inpainting
    </b><br>
    <i><u>Teng-Fang Hsiao</u>, Bo-Kai Ruan, Sung-Lin Tsai, Yi-Lun Wu, Hong-Han Shuai </i><br>
    <i>arXiv preprin, 2024/11 </i><br>
    Enhancing Inpainting Quality without additional computation ğŸ–Œï¸ğŸ’ª0ï¸âƒ£<br> 
    <a href="https://arxiv.org/abs/2412.00427">pdf</a> /
    <a href="https://github.com/BlueDyee/natural-light-attack">GitHub</a> /
  </div>
</div>